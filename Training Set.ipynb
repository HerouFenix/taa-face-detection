{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wider Face: Process Training Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll be developing a way to get face pictures solely based on the Wider Face training set. In order to do this, we've taken some of the pictures in the wider face model and created what we called a positive training set, showing only pictures of the face, and negative training set, showing pictures that don't have a face. We're going to ignore the images with height or width below 16 pixeis. All of the images will then be converted to grayscale for better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(image, start_x, start_y, height, width):\n",
    "    return image[start_y: start_y+height, start_x: start_x+width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_positive_set(file_path, images_path, train_pos_path, val_pos_path, limit_train, limit_val):\n",
    "    count = 0\n",
    "    with open(file_path, \"r\") as file_reader:\n",
    "        while True:\n",
    "            image_path = file_reader.readline().rstrip()\n",
    "            img = cv2.imread(images_path + image_path)\n",
    "            num_faces = int(file_reader.readline())\n",
    "            if num_faces == 0:\n",
    "                #it's a negative image\n",
    "                file_reader.readline()\n",
    "                continue\n",
    "                \n",
    "            if count < limit_train:\n",
    "                for face in range(num_faces):\n",
    "                    image_data = [ int(elem) for elem in file_reader.readline().split()]\n",
    "                    x,y,w,h= image_data[:4]\n",
    "                    if h<32 or w < 32:\n",
    "                        continue\n",
    "                    cv2.imwrite(train_pos_path + \"Image\"+str(count)+\".jpg\", crop_image(img, x, y, h, w))\n",
    "                    count += 1\n",
    "            else:\n",
    "                for face in range(num_faces):\n",
    "                    image_data = [ int(elem) for elem in file_reader.readline().split()]\n",
    "                    x,y,w,h= image_data[:4]\n",
    "                    if h<32 or w < 32:\n",
    "                        continue\n",
    "                    cv2.imwrite(val_pos_path + \"Image\"+str(count-limit_train)+\".jpg\", crop_image(img, x, y, h, w))\n",
    "                    count += 1\n",
    "                    if count > limit_train + limit_val:\n",
    "                        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./Image Resources/Dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = path + \"WIDER_train/images/\"\n",
    "file_path = path + \"wider_face_split/wider_face_train_bbx_gt.txt\"\n",
    "positive_val_path = path + \"WIDER_val/cropped images/positive/\"\n",
    "positive_train_path = path + \"WIDER_train/cropped images/positive/\"\n",
    "train = create_positive_set(file_path, images_path, positive_train_path, positive_val_path, 10000, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersect_images(images_to_avoid, start_x, start_y, width, height):\n",
    "    end_x = start_x + width\n",
    "    end_y = start_y + height\n",
    "    for avoid in images_to_avoid:\n",
    "        center_avoid_x = avoid[0] + avoid[3]//2\n",
    "        center_avoid_y = avoid[1] + avoid[2]//2\n",
    "        if center_avoid_x > start_x and center_avoid_x < end_x \\\n",
    "        and center_avoid_y > start_y and center_avoid_y < end_y:\n",
    "            return True\n",
    "    center_x = start_x + width//2\n",
    "    center_y = start_y + height//2\n",
    "    for avoid in images_to_avoid:\n",
    "        end_avoid_x = avoid[0] + avoid[3]\n",
    "        end_avoid_y = avoid[1] + avoid[2]\n",
    "        if center_x > avoid[0] and center_x < end_avoid_x \\\n",
    "        and center_y > avoid[0] and center_y < end_avoid_y:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_negative_set(file_path, image_set_path, train_save_path, val_save_path, limit_train, limit_val):\n",
    "    count = 0\n",
    "    with open(file_path, \"r\") as file_reader:\n",
    "        while True:\n",
    "            image_path = file_reader.readline().rstrip()\n",
    "            img = cv2.imread(image_set_path + image_path)\n",
    "            try:\n",
    "                img_height, img_width, _ = img.shape\n",
    "            except Exception as e:\n",
    "                print(image_path)\n",
    "                return\n",
    "            num_faces = int(file_reader.readline().rstrip())\n",
    "            #List of images from which I have to avoid\n",
    "            images_to_avoid = []\n",
    "            if num_faces > 5:\n",
    "                for face in range(num_faces):\n",
    "                    file_reader.readline()\n",
    "                continue\n",
    "            else:\n",
    "                if num_faces != 0:\n",
    "                    for face in range(num_faces):\n",
    "                        images_to_avoid.append([int(elem) for elem in file_reader.readline().split()[:4]])\n",
    "                else:\n",
    "                    file_reader.readline().split()\n",
    "            #Going to create 5 images per photo, to force more diversity between photos\n",
    "            if count < limit_train:\n",
    "                for new_img in range(5):\n",
    "                    h = randint(32, 64)\n",
    "                    w = randint(32, 64)\n",
    "                    while True:\n",
    "                        x = randint(0, img_width - w - 1)\n",
    "                        y = randint(0, img_height - h - 1)\n",
    "                        if not intersect_images(images_to_avoid, x, y, h, w):\n",
    "                            break\n",
    "                    cv2.imwrite(train_save_path + \"Image\"+str(count)+\".jpg\", crop_image(img, x, y, h, w))\n",
    "                    count += 1\n",
    "            else:\n",
    "                for new_img in range(5):\n",
    "                    h = randint(32, 64)\n",
    "                    w = randint(32, 64)\n",
    "                    while True:\n",
    "                        x = randint(0, img_width - w - 1)\n",
    "                        y = randint(0, img_height - h - 1)\n",
    "                        if not intersect_images(images_to_avoid, x, y, h, w):\n",
    "                            break\n",
    "                    cv2.imwrite(val_save_path + \"Image\"+str(count-limit_train)+\".jpg\", crop_image(img, x, y, h, w))\n",
    "                    count += 1\n",
    "                    if count > limit_train + limit_val:\n",
    "                        return\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'save_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-2459a0ba1638>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_negative_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"WIDER_train/cropped images/negative/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mval_negative_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"WIDER_val/cropped images/negative/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mcreate_negative_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_negative_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_negative_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-16615b742575>\u001b[0m in \u001b[0;36mcreate_negative_set\u001b[0;34m(file_path, image_set_path, train_save_path, val_save_path, limit_train, limit_val)\u001b[0m\n\u001b[1;32m     33\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mintersect_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_to_avoid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"Image\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".jpg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrop_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m                     \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'save_path' is not defined"
     ]
    }
   ],
   "source": [
    "images_path = path + \"WIDER_train/images/\"\n",
    "file_path = path + \"wider_face_split/wider_face_train_bbx_gt.txt\"\n",
    "train_negative_path = path + \"WIDER_train/cropped images/negative/\"\n",
    "val_negative_path = path + \"WIDER_val/cropped images/negative/\"\n",
    "create_negative_set(file_path, images_path, train_negative_path, val_negative_path, 10000, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
